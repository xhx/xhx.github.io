---
layout: page
title: "Mathematics & Research Notes"
description: "Mathematical notes, research papers, and technical content by Xiaohui Xie"
permalink: /math/
---

# Mathematics & Research Notes

Welcome to my collection of mathematical notes, research papers, and technical content. These notes cover various topics in computer science, machine learning, and applied mathematics.

## Available Notes

### Self-Attention Mechanisms
- **[Self-Attention Approximation Methods](self_attention.md)** - Comprehensive overview of efficient attention mechanisms including kernelization, low-rank approximations, and structured sparsity

### Coming Soon
- More mathematical notes and research papers will be added here
- Topics may include: optimization algorithms, statistical learning theory, computational complexity

## About These Notes

These notes are written for researchers, students, and practitioners in computer science and machine learning. They aim to provide:

- Clear mathematical formulations
- Practical implementation guidance
- Performance comparisons and trade-offs
- References to original research papers

## Contributing

If you find errors or have suggestions for improvements, please feel free to reach out via email or create an issue on the GitHub repository.

---

*Last updated: January 2024*
